{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from xml.etree import ElementTree\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打标签工具\n",
    "[项目地址](https://github.com/wkentaro/labelme)\n",
    "\n",
    "![image](http://raw.githubusercontent.com/tzutalin/labelImg/master/demo/demo3.jpg)\n",
    "\n",
    "```\n",
    "Ctrl + u\tLoad all of the images from a directory\n",
    "Ctrl + r\tChange the default annotation target dir\n",
    "Ctrl + s\tSave\n",
    "Ctrl + d\tCopy the current label and rect box\n",
    "Space\tFlag the current image as verified\n",
    "w\tCreate a rect box\n",
    "d\tNext image\n",
    "a\tPrevious image\n",
    "del\tDelete the selected rect box\n",
    "Ctrl++\tZoom in\n",
    "Ctrl--\tZoom out\n",
    "↑→↓←\tKeyboard arrows to move selected rect box\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改成自己的根路径\n",
    "base_dir = '/Users/mac/tmp/ssd_data4/'\n",
    "\n",
    "# 将图片保存到以下文件夹下面\n",
    "image_save_path = base_dir + 'JPEGImages/' \n",
    "annotations_save_path = base_dir + 'Annotations/' \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.05\n",
    "\n",
    "label_lists = ['little', 'big']\n",
    "\n",
    "layout_path = base_dir + 'Imagesets/Layout/'\n",
    "if not os.path.exists(layout_path): \n",
    "    os.mkdir(layout_path)\n",
    "\n",
    "main_path = base_dir + 'Imagesets/Main/'\n",
    "if not os.path.exists(main_path): \n",
    "    os.mkdir(main_path)\n",
    "    \n",
    "json_save_path = base_dir + 'json/'\n",
    "if not os.path.exists(json_save_path): \n",
    "    os.mkdir(json_save_path)\n",
    "\n",
    "\n",
    "# Sagemaker 所需要的数据集\n",
    "sagemaker_path = base_dir + 'sagemaker/'\n",
    "\n",
    "if not os.path.exists(sagemaker_path): \n",
    "    os.mkdir(sagemaker_path)\n",
    "\n",
    "train_path = sagemaker_path + 'train/'\n",
    "if not os.path.exists(train_path): \n",
    "    os.mkdir(train_path)\n",
    "    \n",
    "train_annotation_path = sagemaker_path + 'train_annotation/'\n",
    "if not os.path.exists(train_annotation_path): \n",
    "    os.mkdir(train_annotation_path)\n",
    "    \n",
    "validation_path = sagemaker_path + 'validation/'\n",
    "if not os.path.exists(validation_path): \n",
    "    os.mkdir(validation_path)\n",
    "    \n",
    "validation_annotation_path = sagemaker_path + 'validation_annotation/'\n",
    "if not os.path.exists(validation_annotation_path): \n",
    "    os.mkdir(validation_annotation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XML_preprocessor(object):\n",
    "\n",
    "    def __init__(self, data_path, label_list, json_save_path):\n",
    "        self.path_prefix = data_path\n",
    "        self.num_classes = len(label_list)\n",
    "        self.data = dict()\n",
    "        self._label_list = label_list\n",
    "        self._json_save_path = json_save_path\n",
    "        self._preprocess_XML()\n",
    "\n",
    "    def _preprocess_XML(self):\n",
    "        filenames = os.listdir(self.path_prefix)\n",
    "        for filename in filenames:\n",
    "\n",
    "            if filename.startswith('.'):\n",
    "                continue\n",
    "            if not filename.endswith('.xml'):\n",
    "                continue\n",
    "\n",
    "\n",
    "            tree = ElementTree.parse(self.path_prefix + filename)\n",
    "            root = tree.getroot()\n",
    "            bounding_boxes = []\n",
    "            one_hot_classes = []\n",
    "            size_tree = root.find('size')\n",
    "            width = float(size_tree.find('width').text)\n",
    "            height = float(size_tree.find('height').text)\n",
    "            for object_tree in root.findall('object'):\n",
    "                for bounding_box in object_tree.iter('bndbox'):\n",
    "                    xmin = float(bounding_box.find('xmin').text)/width\n",
    "                    ymin = float(bounding_box.find('ymin').text)/height\n",
    "                    xmax = float(bounding_box.find('xmax').text)/width\n",
    "                    ymax = float(bounding_box.find('ymax').text)/height\n",
    "                bounding_box = [xmin,ymin,xmax,ymax]\n",
    "                bounding_boxes.append(bounding_box)\n",
    "                class_name = object_tree.find('name').text\n",
    "                one_hot_class = self._to_one_hot(class_name)\n",
    "                one_hot_classes.append(one_hot_class)\n",
    "            image_name = root.find('filename').text\n",
    "            bounding_boxes = np.asarray(bounding_boxes)\n",
    "            one_hot_classes = np.asarray(one_hot_classes)\n",
    "            image_data = np.hstack((bounding_boxes, one_hot_classes))\n",
    "            self.data[image_name] = image_data\n",
    "\n",
    "    def _to_one_hot(self,name):\n",
    "        one_hot_vector = [0] * self.num_classes\n",
    "\n",
    "        _index = self._label_list.index(name)\n",
    "\n",
    "        if _index < 0:\n",
    "            print('Annotations 中的label 和配置文件中 不一致 unknown label: %s' % name)\n",
    "        one_hot_vector[_index] = 1\n",
    "        return one_hot_vector\n",
    "\n",
    "    def _save_file(self, json_object, path):\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(json_object, f)\n",
    "\n",
    "    def to_json(self):\n",
    "\n",
    "        train_val_list = list()\n",
    "\n",
    "        filenames = os.listdir(self.path_prefix)\n",
    "\n",
    "        for filename in filenames:\n",
    "\n",
    "            if filename.startswith('.'):\n",
    "                continue\n",
    "            if not filename.endswith('.xml'):\n",
    "                continue\n",
    "\n",
    "            json_object = dict()\n",
    "            tree = ElementTree.parse(self.path_prefix + filename)\n",
    "            root = tree.getroot()\n",
    "            size_tree = root.find('size')\n",
    "            image_name = root.find('filename').text\n",
    "            json_object['file'] = image_name\n",
    "\n",
    "            width = int(size_tree.find('width').text)\n",
    "            height = int(size_tree.find('height').text)\n",
    "\n",
    "            annotations = list()\n",
    "            categories = list()\n",
    "\n",
    "            for object_tree in root.findall('object'):\n",
    "\n",
    "                annotation = dict()\n",
    "                category = dict()\n",
    "                _top = 0\n",
    "                _left = 0\n",
    "                _width = 0\n",
    "                _height = 0\n",
    "\n",
    "                for bounding_box in object_tree.iter('bndbox'):\n",
    "                    _top = int(bounding_box.find('ymin').text)\n",
    "                    _left = int(bounding_box.find('xmin').text)\n",
    "                    _width = int(bounding_box.find('xmax').text) - _left\n",
    "                    _height = int(bounding_box.find('ymax').text) - _top\n",
    "\n",
    "\n",
    "                class_name = object_tree.find('name').text\n",
    "\n",
    "                class_id = self._label_list.index(class_name)\n",
    "                if class_id < 0:\n",
    "                    print('Annotations 中的label 和配置文件中 不一致 unknown label: %s' % class_name)\n",
    "                annotation['class_id'] = class_id\n",
    "                annotation['top'] = _top\n",
    "                annotation['left'] = _left\n",
    "                annotation['width'] = _width\n",
    "                annotation['height'] = _height\n",
    "                category['class_id'] = class_id\n",
    "                category['name'] = class_name\n",
    "                train_val = dict()\n",
    "                train_val['name'] = image_name.split('.')[0]\n",
    "                train_val['label'] = class_id + 1\n",
    "                train_val_list.append(train_val)\n",
    "\n",
    "\n",
    "                annotations.append(annotation)\n",
    "                categories.append(category)\n",
    "\n",
    "            image_list = list()\n",
    "            image_size = dict()\n",
    "            image_size['width'] = width\n",
    "            image_size['height'] = height\n",
    "            image_size['depth'] = 3\n",
    "            image_list.append(image_size)\n",
    "\n",
    "            json_object['image_size']= image_list\n",
    "            json_object['annotations'] = annotations\n",
    "            json_object['categories'] = categories\n",
    "\n",
    "            path = self._json_save_path + image_name.split('.')[0] +'.json'\n",
    "            self._save_file(json_object, path)\n",
    "\n",
    "        return train_val_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xml = XML_preprocessor(annotations_save_path, label_lists, json_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = xml.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  264\n",
      "val   : 52\n",
      "test  : 13\n",
      "train : 199\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "data_length = len(all_data)\n",
    "random.shuffle(all_data)\n",
    "print('length: ', len(all_data))\n",
    " \n",
    "\n",
    "val_count = int(data_length * val_ratio)\n",
    "test_count = int(data_length * test_ratio)\n",
    "\n",
    "val_list =  all_data[0:val_count]\n",
    "test_list =  all_data[val_count: val_count+test_count]\n",
    "train_list = all_data[val_count+test_count:]\n",
    "\n",
    "print('val   :', len(val_list))\n",
    "print('test  :', len(test_list))\n",
    "print('train :', len(train_list))\n",
    "\n",
    "\n",
    "def dict_to_set(list_dict):\n",
    "    result_set = set()\n",
    "    for i in list_dict:\n",
    "        result_set.add(i['name'])\n",
    "    return result_set\n",
    "\n",
    "\n",
    "dict_to_set(val_list)\n",
    "\n",
    "def write_list_to_file(_list, file_path):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for i in _list:\n",
    "            f.write('{} {}\\n'.format(i['name'], i['label']))\n",
    "\n",
    "def write_set_to_file(_set, file_path):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for i in _set:\n",
    "            f.write('{}\\n'.format(i))            \n",
    "            \n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将数据写入到sagemaker 文件夹里， 给sagemaker 训练使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "train_set = dict_to_set(train_list)\n",
    "val_set = dict_to_set(val_list)\n",
    "test_set = dict_to_set(test_list)\n",
    "\n",
    "for item in train_set:\n",
    "    copyfile('{}{}.jpg'.format(image_save_path, item) ,'{}{}.jpg'.format(train_path, item) )\n",
    "    copyfile('{}{}.json'.format(json_save_path, item) ,'{}{}.json'.format(train_annotation_path, item) )\n",
    "    \n",
    "\n",
    "for item in val_set:\n",
    "    copyfile('{}{}.jpg'.format(image_save_path, item) ,'{}{}.jpg'.format(validation_path, item) )\n",
    "    copyfile('{}{}.json'.format(json_save_path, item) ,'{}{}.json'.format(validation_annotation_path, item) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0002', '0045', '0101', '0025', '0001', '0163', '0029', '0183', '0121', '0135', '0082', '0168', '0019'}\n"
     ]
    }
   ],
   "source": [
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list_to_file(train_list, layout_path + 'train.txt')\n",
    "write_list_to_file(val_list, layout_path + 'trainval.txt')\n",
    "write_list_to_file(test_list, layout_path + 'val.txt')\n",
    "\n",
    "write_set_to_file(dict_to_set(train_list), main_path + 'train.txt')\n",
    "write_set_to_file(dict_to_set(val_list), main_path + 'trainval.txt')\n",
    "write_set_to_file(dict_to_set(test_list), main_path + 'val.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
